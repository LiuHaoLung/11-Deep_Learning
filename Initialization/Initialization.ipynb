{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization is the process in which we set the initial values of weights, as an inappropriate initialization would cause in unoptimizable model.\n",
    "\n",
    "Example for a model with a single hidden layer, let's initialize our weights and biases in such a way that they are equal to a constant, it doesn't matter which constant, as you can see the three hidden units are completely symmetrical with respect to the inputs, each hidden unit is a function of one way coming from x1 and one from x2, if all the weights are equal, there is no reason for the algorithm to learn that h1, h2 and h3 are different, in forward prpagating there is no reason for the algorithm to think that even our outputs are different.\n",
    "\n",
    "Based on this symmetry, in back propagating all the weights are bound to be updates without distinguishing between the different nodes in the net, some optimization would still take place so it won't be the initial value, still the weights would remain useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
