{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Overview of CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs, the convolutional neural networks, with the MNIST dataset, the approach which was simply feedforward neural networks, we flatten the images into a vector of length 784 that way, however we lost the spatial information of every pixels neighborhood of pixels.\n",
    "\n",
    "For example, the 28 and 29 pixels in the vector we ues are next to each other in the vector, but in the picture they are actually quite far away.\n",
    "\n",
    "Furthermore, since we start by taking a linear combination of the inputs, it will search for particular digits in particular places.\n",
    "\n",
    "The convolutional neural networks solves this problem by dealing with the original 28 by 28 photos without flattening them.\n",
    "\n",
    "Instead it applied tiny say 5 by 5 so-called kernels to every possible position of the image, the kernels are like weights.\n",
    "\n",
    "So if we start from the top and continue down, we can count a total of 24 5 by 5 squares, the same applies if we go from the left to the right side.\n",
    "\n",
    "Therefore, the next layer is 24 by 24 which the number of 5 by 5 submatrices, this is called convolution, a layer we get is called the convolutional layer, the number of kernels you choose is a hyperparameters and you are not stricted to a singel kernel.\n",
    "\n",
    "A part of convolution, there is another main step in CNNs, pooling, most commonly we would divide there 24 by 24 squares into multiple 2 by 2 squares without overlapping, and will take the largest number and the 2 by 2 matrix because we assume it is th strongest detail, that's how we reduct the dimensionality of the problem.\n",
    "\n",
    "What makes the issue slightly more complicated though is that most photos have colors which implies that images have height and width but also color or depth, this is third dimension with three variables according to the RGB scheme.\n",
    "\n",
    "Thus the original photo was not in shape 28 by 28 but rather 28 by 28 by 3, that's also where the whole tensor approach fit perfectly.\n",
    "\n",
    "If we convolute and pool for long enough, we can reduce the dimensions to a vector containing one-hot encoding categories, in order to truly get CNNs, it need much more time than a couple of minutes.\n",
    "\n",
    "In general CNNs mainly used an image recognition, because the two major advantages, spatial proximity is preseved, it matters where in the photo we find a certain detail and certain details such as a human eye is looked for everywhere in the photo, thus a face can be recognized everywhere on the image.\n",
    "\n",
    "These two advantages make CNNs predictive power much higher that that of MNs especially when it comes to image related problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
