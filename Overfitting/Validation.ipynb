{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent overfitting, one must be able to identify it first, usually we'll be able to spot overfitting by dividing our available data into three subsets, training, validation and test.\n",
    "\n",
    "The first one is the training data set, as its name suggests, it help us train the model to its final form.\n",
    "\n",
    "The validation data set is the one that will help us detect and prevent overfitting, all the training is done on the training set, in other words, we update the weights and biases for the training set only, every once in a while we stop training for a bit, at this point the model is somewhat trained.\n",
    "\n",
    "What we do next is take the model and apply it to the validation data set, this time we just run it without updating the weights so we only propagate forward not backward, in other words we just calculate its loss function, on average the loss function calculated for the validation set should be the same as the one of the training set.\n",
    "\n",
    "This is logical, as the training and validation sets were extracted from the same initial data set containing the same perceived dependencies.\n",
    "\n",
    "Normally, we would perform this operation many times in the process of creating a good machine learning algorithm, the two loss functions we calculate are referred to as training loss and validation loss and because the data in the training is trained using the gradient descent, each subsequent loss will be lower of equal to the previous one, that's how gradient descent works by definition so we are sure the training loss is being minimized, that's where the validation loss comes to play.\n",
    "\n",
    "At some point the validation loss could be start increasing, that's a red flag, we are overfitting, we are getting better at predicting the training set but we are moving away from the overall logic data, so at this point we should stop training the model.\n",
    "\n",
    "It is extremely important that the model is not trained on validaiton samples, we update the weights and biases for the training set only, if the model is trained on validation sampels, it will eliminate the whole purpose of the above metioned process, the training set and the validation set should be separate without overlapping each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
